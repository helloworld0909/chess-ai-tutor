# GRPO configuration — Qwen3-4B-Thinking-2507 + QLoRA (8-bit, r=32)
# Stage 1: Line generator RL with verifiable chess rewards
#
# Parallelism: single GPU (GRPO rollout generation dominates; DDP adds overhead)
# Rewards: R1 legality (gate) + R2 eval accuracy (0.28) + R3a annotation (0.12)
#          + R4 depth (0.10) + R5 breadth (0.10) + R6 opponent quality (0.10) + R7 relevance (0.05)
# R1=0 short-circuits all downstream rewards to -1.0

model:
  model_name: "checkpoints/qwen3-4b-phase2-lines-sft/checkpoint-350"
  quantization: "8bit"
  attn_implementation: "sdpa"
  torch_dtype: bfloat16

lora:
  r: 64
  alpha: 128
  dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
  bias: none

training:
  train_file: data/processed/lines_sft.jsonl
  eval_file:  data/processed/lines_sft_eval.jsonl

  # Rollout generation
  # generation_batch_size = per_device_train_batch_size (1 process with device_map="auto").
  # num_generations must divide generation_batch_size exactly.
  # 4 completions × 1500 tokens at ~40 tok/s ≈ 2 min/batch — acceptable for RL
  num_generations: 4          # completions sampled per prompt per step
  max_prompt_length: 600      # tokens (system + user only — measured p99=519)
  max_completion_length: 1500 # short thinking (~1000) + 3 lines (~400)

  # Batch
  per_device_train_batch_size: 4   # generation_batch_size=4, divisible by num_generations=4 ✓
  gradient_accumulation_steps: 2   # effective batch = 8 prompts × 4 gen = 32 rollouts

  # Optimiser
  learning_rate: 5.0e-6
  lr_scheduler_type: cosine
  warmup_ratio: 0.05
  num_train_epochs: 1
  optim: adamw_8bit
  weight_decay: 0.01
  max_grad_norm: 0.1

  # GRPO hyperparameters
  beta: 0.04      # KL penalty — keeps policy close to SFT checkpoint
  epsilon: 0.2    # PPO clip ratio

  # Generation sampling
  temperature: 0.9
  top_p: 0.95

  # Infrastructure
  bf16: true
  gradient_checkpointing: true
  seed: 42

  # Logging / checkpointing
  logging_steps: 5
  eval_strategy: steps
  eval_steps: 100
  save_strategy: steps
  save_steps: 100
  save_total_limit: 5

output_dir: checkpoints/qwen3-4b-phase3-grpo

wandb:
  enabled: false
  project: chess-tutor-grpo
  name: qwen3-4b-grpo-phase1
  tags:
    - grpo
    - lines
    - phase1
